
# ðŸ” Customer Churn Prediction Using Machine Learning

This project aims to build a model to predict customer churn based on customer demographics, account information, and service usage using the **Telco Customer Churn dataset** from Kaggle.

> ðŸ“‚ **Dataset Link**: [Telco Customer Churn â€“ Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)

---

## ðŸ“Œ Objective

To build an accurate machine learning model that identifies customers likely to churn so that telecom companies can take proactive steps to retain them.

---

## âš™ï¸ Project Workflow

- Data cleaning and preprocessing
- Label encoding of categorical features
- **Handled class imbalance using downsampling**  
  _(SMOTE caused severe overfitting: Random Forest hit 99.8% train accuracy)_
- Training with multiple classifiers
- **Hyperparameter tuning using `RandomizedSearchCV`** (also tried GridSearchCV)
- Model evaluation using test accuracy, F1-score, recall, and ROC AUC
- Deployment using **Streamlit**

---

## ðŸ§  Models Trained & Compared

| Model         | ROC AUC (Test) | Accuracy | Recall (Churn) | F1-score (Churn) |
| ------------- | ------------- | -------- | -------------- | ---------------- |
| **Random Forest** âœ… | **0.8631** | **76%**   | **86%**         | **65%**           |
| XGBoost       | 0.8580        | 75%      | 82%             | 63%              |
| CatBoost      | 0.8594        | 75%      | 83%             | 63%              |

> ðŸ”Ž **Best model**: Random Forest â€“ highest ROC AUC, best balance of recall and F1-score

---

## ðŸ“ˆ Model Evaluation (Random Forest)

```
Train ROC AUC: 0.7921
Test ROC AUC: 0.8631
Accuracy: 76%
Recall (Churn): 86%
F1-score (Churn): 65%
```

---

## ðŸ§ª Preprocessing Details

| Step                | Description |
|--------------------|-------------|
| Categorical Encoding | Label Encoding via `sklearn.preprocessing.LabelEncoder` |
| SMOTE   | Used **SMOTE for upsampling**, result gave better recall for non-churn but my aim was to better predict churn, so preferred **downsampling** |
| Class Imbalance     | Used **downsampling** to balance churn/no-churn classes |
| Hyperparameter Tuning | Used `RandomizedSearchCV` with `StratifiedKFold` |
| Feature Engineering | Tried binning `tenure` into groups, but found **negligible impact**, so reverted |

---

## ðŸš€ Streamlit Web App

A user-friendly web app is created using **Streamlit** to allow real-time predictions.

### ðŸ”§ Features:
- Choose between **Random Forest**, **XGBoost**, or **CatBoost**
- Input form for customer attributes
- Shows prediction result and churn probability
- All models, encoders, and scalers are reused via `pickle`

### ðŸ“Ž To Run the App:

```bash
# Step 1: Install dependencies
pip install -r requirements.txt

# Step 2: Run the app
streamlit run app.py
```

---
### Link for streamlit app 

[Try mychurn predictor](https://mychurn.streamlit.app/)

---

## ðŸ§° Tech Stack

- **Python 3.11**
- **Scikit-learn** (Label Encoding, RandomForest, CV tools)
- **CatBoost**, **XGBoost**
- **Streamlit** â€“ for web UI
- **Pickle** â€“ for model serialization
- **Pandas**, **NumPy**, **Seaborn**, **Matplotlib**

---

## ðŸ›  File Structure

```
Churn_predictor/
â”œâ”€â”€ app.py                          # Streamlit frontend
â”œâ”€â”€ customer_churn_randomforest.pkl
â”œâ”€â”€ customer_churn_catboost.pkl
â”œâ”€â”€ customer_churn_xgboost.pkl
â”œâ”€â”€ encoders.pkl
â”œâ”€â”€ monthlycharges_scaler.pkl
â”œâ”€â”€ totalcharges_scaler.pkl
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸ’¡ Future Work

- Try to reduce overfitting
- Explore **stacking ensemble** (e.g. RF + XGB + CatBoost)
- Dockerize for scalable cloud deployment
- Add logging and analytics dashboard to track model predictions

---

## ðŸ™Œ Acknowledgements

- [Telco Customer Churn Dataset â€“ Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
- Scikit-learn, Streamlit, XGBoost, CatBoost

---

